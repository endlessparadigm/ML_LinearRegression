# ML_Model_Dataset
Creating a machine learning model and training the dataset.

In my ambition to learn more about AI and ML related concepts, I made a small write up related to obtaining a dataset, defining/training a model, and applying statistical methodology and ML fundamentals in hopes of learning more about the subject. See below.

[Abstract]
(Made-up business case) - We work at a mid-sized firm that provides frozen products at stores or grocery stores. One product in particular is a lunch plate containing portions of avocadoes. Due to the high cost of avocadoes (indeed with respect to the cost of the other ingredients contained in the plate), the business has requested for a predictive analytics model to be applied to the ongoing cost of the ingredient to ensure product profitability is kept. (Ex: Changing the tolerance of the mix of ingredients present while retaining the appropriate mix of ingredients as expected by the Brand based on present market need and sale value at the store). 

[Creating and Obtaining the Dataset]
For this we will need to obtain a dataset of the avocadoes purchased over time, along with the sale value.

[CSV]
The above CSV was obtained from Kaggle [here](https://www.kaggle.com/datasets/neuromusic/avocado-prices). (..and as mentioned, is entirely unrelated to the made-up business case)

[Creating the dataset]
With the list provided to us, this should be as simple as applying some statistical models and retrieving the running average and perhaps near-market time volatility by the end of the day! (I'll be home by 5!) 

Unfortunately we first need to acquire or assume the dataset, understand or interpret it manually, and then prepare or clean it up so it may be used as an appropriate model. Great!

[Assessing the Data]
Without going too in depth here, the data thankfully came with a description of the columns. This includes fields like Date, AveragePrice (average price of 1 avocado), Total Volume (total number of avocados sold), and other fields like Small Bags (# of avocadoes sold in a bunch, or bag).

Some of these fields seem strange or unecessary. I also don't know how accurate the data is. Were the counts made at the store or by shorthand at the market? It's possible that the results are estimated (in which case we would want to accomodate for such 'innacuracy' of the source data).



[Cleaning the Data]
Tools: Python, Pandas, 
3. Train the model (which will we use?)

[1.5]: https://raw.githubusercontent.com/Ignitetechnologies/Windows-Privilege-Escalation/main/linked.png

# Follow us on [![alt text][1.1]][1] [![alt text][1.3]][1.4] [![alt text][1.5]][1.6]

![image](https://github.com/Ignitetechnologies/Vulnhub-CTF-Writeups/blob/master/vulnhub.png?raw=true)

